{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Natural Capital Pipeline (Colab)\n",
        "この順番で `Input -> Output` を繰り返してください。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Input 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Output 1\n",
        "`Mounted at /content/drive`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Input 2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2) プロジェクトフォルダを作成\n",
        "import os\n",
        "PROJECT_DIR = \"/content/drive/MyDrive/pj-TERM\"\n",
        "os.makedirs(PROJECT_DIR, exist_ok=True)\n",
        "%cd /content/drive/MyDrive/pj-TERM\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Output 2\n",
        "`/content/drive/MyDrive/pj-TERM`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Input 3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile /content/drive/MyDrive/pj-TERM/natural_capital_pipeline.py\n",
        "#!/usr/bin/env python3\n",
        "from __future__ import annotations\n",
        "\n",
        "# コマンドライン引数、CSV/JSON入出力、日付計算に使う標準ライブラリ\n",
        "import argparse\n",
        "import csv\n",
        "import json\n",
        "from dataclasses import dataclass, field\n",
        "from datetime import date, datetime, timedelta\n",
        "from pathlib import Path\n",
        "from typing import Any, Dict, List\n",
        "\n",
        "# 数値計算\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# 設定用データクラス\n",
        "\n",
        "@dataclass\n",
        "class PeriodConfig:\n",
        "    # 分析期間\n",
        "    start_date: str\n",
        "    end_date: str\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class DataConfig:\n",
        "    # 出力先ディレクトリ設定\n",
        "    cache_dir: str = \"./cache\"\n",
        "    outputs_subdir: str = \"fujisawa_demo\"\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class ModelConfig:\n",
        "    # モデル側の主要パラメータ\n",
        "    lookback_weeks: int = 12\n",
        "    garch_forecast_horizon: int = 8\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class FinanceConfig:\n",
        "    # 金融シグナル計算に使うパラメータ\n",
        "    derivative_notional: float = 1_000_000.0\n",
        "    derivative_vol_quantile: float = 0.9\n",
        "    derivative_max_payout_ratio: float = 0.2\n",
        "    bond_base_coupon: float = 0.045\n",
        "    bond_step_down_bps: float = 30.0\n",
        "    bond_step_up_bps: float = 40.0\n",
        "    bond_target_quarterly_growth: float = 0.01\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class PipelineConfig:\n",
        "    # 全体設定をまとめる\n",
        "    period: PeriodConfig\n",
        "    data: DataConfig = field(default_factory=DataConfig)\n",
        "    model: ModelConfig = field(default_factory=ModelConfig)\n",
        "    finance: FinanceConfig = field(default_factory=FinanceConfig)\n",
        "\n",
        "\n",
        "def load_config(path: Path) -> PipelineConfig:\n",
        "    # JSON設定ファイルを読み込んで dataclass に変換\n",
        "    raw = json.loads(path.read_text(encoding=\"utf-8\"))\n",
        "    return PipelineConfig(\n",
        "        period=PeriodConfig(**raw[\"period\"]),\n",
        "        data=DataConfig(**raw.get(\"data\", {})),\n",
        "        model=ModelConfig(**raw.get(\"model\", {})),\n",
        "        finance=FinanceConfig(**raw.get(\"finance\", {})),\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "# 日付・入出力を行う\n",
        "\n",
        "def parse_date(s: str) -> date:\n",
        "    # \"YYYY-MM-DD\" 文字列を date に変換\n",
        "    return datetime.strptime(s, \"%Y-%m-%d\").date()\n",
        "\n",
        "\n",
        "def date_to_str(d: date) -> str:\n",
        "    # date を \"YYYY-MM-DD\" に変換\n",
        "    return d.strftime(\"%Y-%m-%d\")\n",
        "\n",
        "\n",
        "def week_start(d: date) -> date:\n",
        "    # その週の月曜日を返す\n",
        "    return d - timedelta(days=d.weekday())\n",
        "\n",
        "\n",
        "def week_range(start: date, end: date) -> List[date]:\n",
        "    # start〜end の週次（月曜）リストを作る\n",
        "    cur = week_start(start)\n",
        "    out = []\n",
        "    while cur <= end:\n",
        "        out.append(cur)\n",
        "        cur += timedelta(days=7)\n",
        "    return out\n",
        "\n",
        "\n",
        "def ensure_dir(path: Path) -> None:\n",
        "    # ディレクトリがなければ作成\n",
        "    path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "\n",
        "def write_json(path: Path, obj: Any) -> None:\n",
        "    # JSONファイル保存\n",
        "    ensure_dir(path.parent)\n",
        "    path.write_text(json.dumps(obj, ensure_ascii=True, indent=2), encoding=\"utf-8\")\n",
        "\n",
        "\n",
        "def read_json(path: Path) -> Any:\n",
        "    # JSONファイル読み込み\n",
        "    return json.loads(path.read_text(encoding=\"utf-8\"))\n",
        "\n",
        "\n",
        "def write_csv(path: Path, headers: List[str], rows: List[List[Any]]) -> None:\n",
        "    # CSVファイル保存\n",
        "    ensure_dir(path.parent)\n",
        "    with path.open(\"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
        "        w = csv.writer(f)\n",
        "        w.writerow(headers)\n",
        "        for row in rows:\n",
        "            w.writerow(row)\n",
        "\n",
        "\n",
        "# 合成データ作成\n",
        "\n",
        "def synthetic_weekly_rows(cfg: PipelineConfig) -> List[Dict[str, Any]]:\n",
        "    # 期間から週次の疑似特徴量を作る（実データ取得の代替）\n",
        "    weeks = week_range(parse_date(cfg.period.start_date), parse_date(cfg.period.end_date))\n",
        "    n = max(1, len(weeks))\n",
        "    rows = []\n",
        "    for i, w in enumerate(weeks):\n",
        "        t = i / max(1, n - 1)  # 0〜1の進行度\n",
        "        rows.append({\n",
        "            \"week_start\": date_to_str(w),\n",
        "            \"s2_green_fraction\": 0.45 + 0.2 * t,\n",
        "            \"s2_fragmentation\": 0.30 - 0.12 * t,\n",
        "            \"gbif_species_richness\": 10 + 2.5 * np.sin(i / 4.0),\n",
        "            \"weather_soil_moisture\": 0.24 + 0.05 * np.sin(i / 8.0),\n",
        "            \"weather_temp_stress\": 0.45 + 0.08 * np.sin(i / 9.0),\n",
        "        })\n",
        "    return rows\n",
        "\n",
        "\n",
        "#t = i / (n-1)\n",
        "#期間の先頭→末尾を 0→1 に正規化して、ゆるい長期トレンドを作るため。\n",
        "#0.45 + 0.2*t（s2_green_fraction）\n",
        "#範囲を 0.45〜0.65 にして、0〜1の中で自然な「やや改善」トレンドを表現。#0.30 - 0.12*t（s2_fragmentation）\n",
        "#範囲を 0.30〜0.18 にして、緑被率と逆方向に動くように設定。\n",
        "#（gbif_species_richness）\n",
        "#平均10、振幅2.5で季節的な上下を作る（急変しすぎない）。\n",
        "#8.0)（weather_soil_moisture）\n",
        "#平均0.24、振幅0.05で湿潤度のゆるい周期変動。\n",
        "#9.0)（weather_temp_stress）\n",
        "#平均0.45、振幅0.08で温度ストレスの中程度変動。\n",
        "\n",
        "#要検証！\n",
        "\n",
        "\n",
        "# 指数（インデックス）計算\n",
        "\n",
        "def build_natural_capital_index(weekly_rows: List[Dict[str, Any]], lookback_weeks: int = 12) -> Dict[str, Any]:\n",
        "    # 引数互換のため残す（この簡易版では未使用）\n",
        "    del lookback_weeks\n",
        "\n",
        "    # 入力が空なら空を返す\n",
        "    if not weekly_rows:\n",
        "        return {\"rows\": [], \"feature_names\": [], \"weights\": []}\n",
        "\n",
        "    # week_start 以外を特徴量として使う\n",
        "    feature_names = [k for k in weekly_rows[0].keys() if k != \"week_start\"]\n",
        "    x = np.array([[float(r[k]) for k in feature_names] for r in weekly_rows], dtype=np.float64)\n",
        "\n",
        "    # 特徴量ごとに標準化（z-score）\n",
        "    mu = x.mean(axis=0)\n",
        "    sd = x.std(axis=0)\n",
        "    sd[sd < 1e-9] = 1.0\n",
        "    z = (x - mu) / sd\n",
        "\n",
        "    # 特徴量を等重み平均してスコア化\n",
        "    score = z.mean(axis=1)\n",
        "\n",
        "    # 週次リターンをスコア差分から作る\n",
        "    ret = np.zeros(len(score), dtype=np.float64)\n",
        "    if len(score) > 1:\n",
        "        ret[1:] = np.clip(0.08 * np.diff(score), -0.3, 0.3)\n",
        "\n",
        "    # リターンを累積して指数レベルを作る（初期値100）\n",
        "    idx = np.zeros(len(score), dtype=np.float64)\n",
        "    idx[0] = 100.0\n",
        "    for i in range(1, len(idx)):\n",
        "        idx[i] = max(1e-6, idx[i - 1] * (1.0 + ret[i]))\n",
        "\n",
        "    # 出力行に指数とリターンを追加\n",
        "    out_rows = []\n",
        "    for i, row in enumerate(weekly_rows):\n",
        "        r = dict(row)\n",
        "        r[\"natural_capital_index\"] = float(idx[i])\n",
        "        r[\"ecological_return\"] = float(ret[i])\n",
        "        out_rows.append(r)\n",
        "\n",
        "    # 等重み（説明用に返す）\n",
        "    weights = [1.0 / len(feature_names)] * len(feature_names)\n",
        "    return {\"rows\": out_rows, \"feature_names\": feature_names, \"weights\": weights}\n",
        "\n",
        "\n",
        "# GARCH(1,1)から考える\n",
        "\n",
        "class Garch11:\n",
        "    def __init__(self, alpha: float = 0.08, beta: float = 0.9):\n",
        "        # GARCHパラメータ初期値\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.omega = 0.0\n",
        "        self.mu = 0.0\n",
        "        self.sigma2 = np.array([], dtype=np.float64)\n",
        "\n",
        "    def fit(self, returns: np.ndarray) -> \"Garch11\":\n",
        "        # リターン列から条件付き分散系列 sigma2 を推定\n",
        "        r = np.asarray(returns, dtype=np.float64)\n",
        "        self.mu = float(np.mean(r))\n",
        "        e = r - self.mu\n",
        "        var = float(np.var(e)) + 1e-8\n",
        "\n",
        "        # 定常条件 alpha + beta < 1 を守る\n",
        "        if self.alpha + self.beta >= 0.995:\n",
        "            self.beta = 0.995 - self.alpha\n",
        "\n",
        "        # 長期分散に基づき omega を設定\n",
        "        self.omega = max(1e-10, var * (1.0 - self.alpha - self.beta))\n",
        "\n",
        "        # 再帰計算\n",
        "        s2 = np.zeros(len(r), dtype=np.float64)\n",
        "        s2[0] = var\n",
        "        for t in range(1, len(r)):\n",
        "            s2[t] = self.omega + self.alpha * (e[t - 1] ** 2) + self.beta * s2[t - 1]\n",
        "            s2[t] = max(1e-10, s2[t])\n",
        "        self.sigma2 = s2\n",
        "        return self\n",
        "\n",
        "    @staticmethod\n",
        "    def forecast(model: \"Garch11\", horizon: int) -> np.ndarray:\n",
        "        # 将来horizon週の分散予測\n",
        "        h = max(1, int(horizon))\n",
        "        if len(model.sigma2) == 0:\n",
        "            return np.full(h, 1e-6, dtype=np.float64)\n",
        "\n",
        "        p = min(0.999, model.alpha + model.beta)\n",
        "        long_run = model.omega / max(1e-8, 1.0 - p)\n",
        "\n",
        "        out = np.zeros(h, dtype=np.float64)\n",
        "        prev = float(model.sigma2[-1])\n",
        "        for i in range(h):\n",
        "            prev = long_run + p * (prev - long_run)\n",
        "            out[i] = max(1e-10, prev)\n",
        "        return out\n",
        "\n",
        "\n",
        "# 金融シグナル計算\n",
        "\n",
        "\n",
        "def build_finance_signals(cfg: PipelineConfig, vol_hist: np.ndarray, vol_fore: np.ndarray) -> Dict[str, Any]:\n",
        "    # 履歴分散の上位quantileを閾値としてトリガー判定\n",
        "    threshold = float(np.quantile(vol_hist, cfg.finance.derivative_vol_quantile))\n",
        "    triggered = bool(np.max(vol_fore) > threshold)\n",
        "\n",
        "    # 閾値超過率に応じてペイアウトを計算\n",
        "    excess = max(0.0, float(np.max(vol_fore) / max(1e-10, threshold) - 1.0))\n",
        "    payout_ratio = min(cfg.finance.derivative_max_payout_ratio, 0.5 * excess)\n",
        "    payout = payout_ratio * cfg.finance.derivative_notional\n",
        "\n",
        "    # 直近13週とその前13週の比較でクーポン上下\n",
        "    coupon = cfg.finance.bond_base_coupon\n",
        "    recent = float(np.mean(vol_hist[-13:])) if len(vol_hist) >= 13 else float(np.mean(vol_hist))\n",
        "    prev = float(np.mean(vol_hist[-26:-13])) if len(vol_hist) >= 26 else recent\n",
        "    growth_proxy = (prev - recent) / prev if prev > 1e-10 else 0.0\n",
        "    if growth_proxy >= cfg.finance.bond_target_quarterly_growth:\n",
        "        coupon -= cfg.finance.bond_step_down_bps / 10000.0\n",
        "    else:\n",
        "        coupon += cfg.finance.bond_step_up_bps / 10000.0\n",
        "\n",
        "    return {\n",
        "        \"derivative\": {\n",
        "            \"vol_threshold\": threshold,\n",
        "            \"triggered\": triggered,\n",
        "            \"payout_ratio\": payout_ratio,\n",
        "            \"payout_amount\": payout,\n",
        "        },\n",
        "        \"nature_bond\": {\n",
        "            \"base_coupon\": cfg.finance.bond_base_coupon,\n",
        "            \"final_coupon\": coupon,\n",
        "            \"quarterly_growth_proxy\": growth_proxy,\n",
        "        },\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "# キャッシュ生成・読み込\n",
        "\n",
        "def build_data_cache(cfg: PipelineConfig, out_root: Path) -> Dict[str, Any]:\n",
        "    # raw配下に簡易データを書き出す\n",
        "    raw = out_root / \"raw\"\n",
        "    ensure_dir(raw)\n",
        "    weekly_rows = synthetic_weekly_rows(cfg)\n",
        "\n",
        "    write_json(raw / \"sentinel2_items.json\", {\"features\": []})\n",
        "    write_json(raw / \"sentinel1_items.json\", {\"features\": []})\n",
        "    write_json(raw / \"sentinel2_thumbnails.json\", [])\n",
        "    write_json(raw / \"sentinel1_thumbnails.json\", [])\n",
        "    write_json(raw / \"gbif_occurrences.json\", {\"results\": []})\n",
        "    write_json(raw / \"gbif_images.json\", [])\n",
        "    write_json(raw / \"weather_daily.json\", {\"daily\": {}})\n",
        "    write_json(raw / \"weekly_rows.json\", weekly_rows)\n",
        "    return {\"weekly_rows\": weekly_rows}\n",
        "\n",
        "\n",
        "def load_cached_data(out_root: Path) -> Dict[str, Any]:\n",
        "    # 週次行キャッシュを読み込む\n",
        "    p = out_root / \"raw\" / \"weekly_rows.json\"\n",
        "    return {\"weekly_rows\": read_json(p) if p.exists() else []}\n",
        "\n",
        "\n",
        "# モデリング実行\n",
        "\n",
        "def run_modeling_from_data(cfg: PipelineConfig, out_root: Path, data_bundle: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    # データがなければ合成データで補完\n",
        "    weekly_rows = data_bundle.get(\"weekly_rows\", []) or synthetic_weekly_rows(cfg)\n",
        "\n",
        "    # インデックス計算\n",
        "    idx_pack = build_natural_capital_index(weekly_rows, cfg.model.lookback_weeks)\n",
        "    idx_rows = idx_pack[\"rows\"]\n",
        "\n",
        "    # GARCH推定と予測\n",
        "    returns = np.array([r[\"ecological_return\"] for r in idx_rows], dtype=np.float64)\n",
        "    g = Garch11().fit(returns)\n",
        "    g_fore = Garch11.forecast(g, cfg.model.garch_forecast_horizon)\n",
        "\n",
        "    # Transformer代替: 直近4点平均を水平予測\n",
        "    tf_like_fore = np.full(cfg.model.garch_forecast_horizon, float(np.mean(g.sigma2[-4:])), dtype=np.float64)\n",
        "\n",
        "    # 金融シグナル\n",
        "    signals = build_finance_signals(cfg, g.sigma2, tf_like_fore)\n",
        "\n",
        "    # 出力保存\n",
        "    derived = out_root / \"derived\"\n",
        "    ensure_dir(derived)\n",
        "\n",
        "    headers = list(weekly_rows[0].keys())\n",
        "    write_csv(derived / \"features_weekly.csv\", headers, [[r[k] for k in headers] for r in weekly_rows])\n",
        "\n",
        "    write_csv(\n",
        "        derived / \"natural_capital_index.csv\",\n",
        "        [\"week_start\", \"natural_capital_index\", \"ecological_return\"],\n",
        "        [[r[\"week_start\"], r[\"natural_capital_index\"], r[\"ecological_return\"]] for r in idx_rows],\n",
        "    )\n",
        "\n",
        "    write_csv(\n",
        "        derived / \"volatility_forecast.csv\",\n",
        "        [\"horizon_week\", \"garch_sigma2\", \"transformer_sigma2\"],\n",
        "        [[i + 1, float(g_fore[i]), float(tf_like_fore[i])] for i in range(cfg.model.garch_forecast_horizon)],\n",
        "    )\n",
        "\n",
        "    write_json(derived / \"finance_signals.json\", signals)\n",
        "    write_json(derived / \"model_meta.json\", {\"garch\": {\"mu\": g.mu, \"omega\": g.omega, \"alpha\": g.alpha, \"beta\": g.beta}})\n",
        "\n",
        "    # まとめ指標\n",
        "    summary = {\n",
        "        \"n_weeks\": len(idx_rows),\n",
        "        \"last_index\": float(idx_rows[-1][\"natural_capital_index\"]),\n",
        "        \"last_return\": float(idx_rows[-1][\"ecological_return\"]),\n",
        "        \"last_garch_sigma2\": float(g.sigma2[-1]),\n",
        "        \"max_forecast_sigma2\": float(np.max(tf_like_fore)),\n",
        "    }\n",
        "    write_json(derived / \"summary.json\", summary)\n",
        "    return summary\n",
        "\n",
        "\n",
        "\n",
        "# CLI\n",
        "\n",
        "def parse_args() -> argparse.Namespace:\n",
        "    # 実行モードと設定ファイルを受け取る\n",
        "    p = argparse.ArgumentParser()\n",
        "    p.add_argument(\"command\", choices=[\"run\", \"fetch\", \"from-cache\"])\n",
        "    p.add_argument(\"--config\", required=True)\n",
        "    return p.parse_args()\n",
        "\n",
        "\n",
        "def main() -> None:\n",
        "    args = parse_args()\n",
        "    cfg = load_config(Path(args.config))\n",
        "    out_root = Path(cfg.data.cache_dir) / cfg.data.outputs_subdir\n",
        "\n",
        "    # fetch はデータ作成だけ\n",
        "    if args.command == \"fetch\":\n",
        "        build_data_cache(cfg, out_root)\n",
        "        print(f\"[ok] cached raw data at: {out_root / 'raw'}\")\n",
        "        return\n",
        "\n",
        "    # from-cache はキャッシュ読み込み（なければ作る）\n",
        "    if args.command == \"from-cache\":\n",
        "        data = load_cached_data(out_root)\n",
        "        if not data[\"weekly_rows\"]:\n",
        "            data = build_data_cache(cfg, out_root)\n",
        "    else:\n",
        "        # run は毎回作り直し\n",
        "        data = build_data_cache(cfg, out_root)\n",
        "\n",
        "    # モデル実行\n",
        "    summary = run_modeling_from_data(cfg, out_root, data)\n",
        "    print(json.dumps(summary, ensure_ascii=True, indent=2))\n",
        "    print(f\"[ok] outputs at: {out_root}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Output 3\n",
        "`Overwriting /content/drive/MyDrive/pj-TERM/natural_capital_pipeline.py`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Input 4\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile /content/drive/MyDrive/pj-TERM/config_example.json\n",
        "{\n",
        "  \"period\": {\n",
        "    \"start_date\": \"2024-01-01\",\n",
        "    \"end_date\": \"2025-12-31\"\n",
        "  },\n",
        "  \"data\": {\n",
        "    \"cache_dir\": \"./cache\",\n",
        "    \"outputs_subdir\": \"fujisawa_demo\"\n",
        "  },\n",
        "  \"model\": {\n",
        "    \"lookback_weeks\": 7,\n",
        "    \"garch_forecast_horizon\": 8\n",
        "  }\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Output 4\n",
        "`Overwriting /content/drive/MyDrive/pj-TERM/config_example.json`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Input 5\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python /content/drive/MyDrive/pj-TERM/natural_capital_pipeline.py run --config /content/drive/MyDrive/pj-TERM/config_example.json\n",
        "!python /content/drive/MyDrive/pj-TERM/natural_capital_pipeline.py from-cache --config /content/drive/MyDrive/pj-TERM/config_example.json\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Output 5\n",
        "サマリJSONが2回表示され、`[ok] outputs at: cache/fujisawa_demo`\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"n_weeks\": 105,\n",
        "  \"last_index\": 100.67292210309215,\n",
        "  \"last_return\": 0.008085509547213057,\n",
        "  \"last_garch_sigma2\": 4.231563940382314e-05,\n",
        "  \"max_forecast_sigma2\": 3.762811892237847e-05\n",
        "}\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Input 6\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "\n",
        "base = Path(\"/content/drive/MyDrive/pj-TERM/cache/fujisawa_demo/derived\")\n",
        "\n",
        "idx = pd.read_csv(base / \"natural_capital_index.csv\")\n",
        "vol = pd.read_csv(base / \"volatility_forecast.csv\")\n",
        "\n",
        "idx[\"week_start\"] = pd.to_datetime(idx[\"week_start\"])\n",
        "\n",
        "fig, axes = plt.subplots(2, 1, figsize=(12, 8), constrained_layout=True)\n",
        "\n",
        "# 1) 自然資本インデックス + リターン\n",
        "ax1 = axes[0]\n",
        "ax1.plot(idx[\"week_start\"], idx[\"natural_capital_index\"], label=\"Natural Capital Index\")\n",
        "ax1.set_title(\"Natural Capital Index\")\n",
        "ax1.set_xlabel(\"Week\")\n",
        "ax1.set_ylabel(\"Index Level\")\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "ax1b = ax1.twinx()\n",
        "ax1b.plot(idx[\"week_start\"], idx[\"ecological_return\"], linestyle=\"--\", label=\"Ecological Return\")\n",
        "ax1b.set_ylabel(\"Return\")\n",
        "\n",
        "lines1, labels1 = ax1.get_legend_handles_labels()\n",
        "lines2, labels2 = ax1b.get_legend_handles_labels()\n",
        "ax1.legend(lines1 + lines2, labels1 + labels2, loc=\"best\")\n",
        "\n",
        "# 2) 予測ボラティリティ\n",
        "ax2 = axes[1]\n",
        "ax2.plot(vol[\"horizon_week\"], vol[\"garch_sigma2\"], marker=\"o\", label=\"GARCH Sigma^2\")\n",
        "ax2.plot(vol[\"horizon_week\"], vol[\"transformer_sigma2\"], marker=\"s\", label=\"Transformer Sigma^2\")\n",
        "ax2.set_title(\"Volatility Forecast\")\n",
        "ax2.set_xlabel(\"Horizon Week\")\n",
        "ax2.set_ylabel(\"Variance\")\n",
        "ax2.grid(True, alpha=0.3)\n",
        "ax2.legend(loc=\"best\")\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Output 6\n",
        "`Natural Capital Index` と `Volatility Forecast` の2段プロット\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Input 7\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Colabでこの1セルを実行してください（Python 3.12対応版）\n",
        "import sys\n",
        "import importlib.util\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "\n",
        "SCRIPT = \"/content/drive/MyDrive/pj-TERM/natural_capital_pipeline.py\"\n",
        "CONFIG = \"/content/drive/MyDrive/pj-TERM/config_example.json\"\n",
        "\n",
        "# --- 安全にモジュール読込（dataclassエラー回避） ---\n",
        "sys.modules.pop(\"ncp\", None)\n",
        "spec = importlib.util.spec_from_file_location(\"ncp\", SCRIPT)\n",
        "ncp = importlib.util.module_from_spec(spec)\n",
        "sys.modules[\"ncp\"] = ncp\n",
        "spec.loader.exec_module(ncp)\n",
        "\n",
        "cfg = ncp.load_config(Path(CONFIG))\n",
        "rows = ncp.synthetic_weekly_rows(cfg)\n",
        "\n",
        "def build_returns(rows, return_scale, return_clip):\n",
        "    feature_names = [k for k in rows[0].keys() if k != \"week_start\"]\n",
        "    x = np.array([[float(r[k]) for k in feature_names] for r in rows], dtype=np.float64)\n",
        "    mu = x.mean(axis=0)\n",
        "    sd = x.std(axis=0)\n",
        "    sd[sd < 1e-9] = 1.0\n",
        "    z = (x - mu) / sd\n",
        "    score = z.mean(axis=1)\n",
        "\n",
        "    ret = np.zeros(len(score), dtype=np.float64)\n",
        "    if len(score) > 1:\n",
        "        ret[1:] = np.clip(return_scale * np.diff(score), -return_clip, return_clip)\n",
        "    return ret\n",
        "\n",
        "def one_step_var_rmse(returns, alpha, beta):\n",
        "    n = len(returns)\n",
        "    split = max(12, int(n * 0.7))\n",
        "    if split >= n - 2:\n",
        "        return np.inf\n",
        "\n",
        "    if alpha <= 0 or beta <= 0 or alpha + beta >= 0.995:\n",
        "        return np.inf\n",
        "\n",
        "    tr = returns[:split]\n",
        "    va = returns[split:]\n",
        "\n",
        "    mu = float(np.mean(tr))\n",
        "    e = tr - mu\n",
        "    var0 = float(np.var(e)) + 1e-8\n",
        "    omega = max(1e-10, var0 * (1.0 - alpha - beta))\n",
        "\n",
        "    s2 = var0\n",
        "    e_prev = float(e[-1]) if len(e) else 0.0\n",
        "    pred = []\n",
        "    for r in va:\n",
        "        s2 = max(1e-10, omega + alpha * (e_prev ** 2) + beta * s2)\n",
        "        pred.append(s2)\n",
        "        e_prev = float(r - mu)\n",
        "\n",
        "    realized = (va - mu) ** 2\n",
        "    return float(np.sqrt(np.mean((np.array(pred) - realized) ** 2)))\n",
        "\n",
        "# ベースライン\n",
        "baseline = {\n",
        "    \"return_scale\": 0.08,\n",
        "    \"return_clip\": 0.30,\n",
        "    \"alpha\": 0.08,\n",
        "    \"beta\": 0.90,\n",
        "}\n",
        "r0 = build_returns(rows, baseline[\"return_scale\"], baseline[\"return_clip\"])\n",
        "baseline_rmse = one_step_var_rmse(r0, baseline[\"alpha\"], baseline[\"beta\"])\n",
        "\n",
        "# ランダムサーチ\n",
        "rng = np.random.default_rng(42)\n",
        "best = {\"rmse\": np.inf}\n",
        "\n",
        "for _ in range(600):\n",
        "    p = {\n",
        "        \"return_scale\": float(rng.uniform(0.03, 0.14)),\n",
        "        \"return_clip\": float(rng.uniform(0.10, 0.40)),\n",
        "        \"alpha\": float(rng.uniform(0.03, 0.20)),\n",
        "        \"beta\": float(rng.uniform(0.70, 0.96)),\n",
        "    }\n",
        "    if p[\"alpha\"] + p[\"beta\"] >= 0.995:\n",
        "        continue\n",
        "\n",
        "    rr = build_returns(rows, p[\"return_scale\"], p[\"return_clip\"])\n",
        "    rmse = one_step_var_rmse(rr, p[\"alpha\"], p[\"beta\"])\n",
        "    if rmse < best[\"rmse\"]:\n",
        "        best = {**p, \"rmse\": rmse}\n",
        "\n",
        "print(\"baseline:\", {**baseline, \"rmse\": baseline_rmse})\n",
        "print(\"best:\", best)\n",
        "\n",
        "print(\"\\n--- 置換用 ---\")\n",
        "print(f'ret[1:] = np.clip({best[\"return_scale\"]:.6f} * np.diff(score), -{best[\"return_clip\"]:.6f}, {best[\"return_clip\"]:.6f})')\n",
        "print(f'g = Garch11(alpha={best[\"alpha\"]:.6f}, beta={best[\"beta\"]:.6f}).fit(returns)')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Output 7\n",
        "`baseline` と `best`、置換用2行が表示\n",
        "\n",
        "- baseline RMSE: `2.7193715012009834e-05`\n",
        "- best params:\n",
        "  - `return_scale = 0.030182677844228057`\n",
        "  - `return_clip = 0.13362111129960927`\n",
        "  - `alpha = 0.1766699758359493`\n",
        "  - `beta = 0.7003205962530961`\n",
        "  - `rmse = 3.240149354737738e-06`\n",
        "\n",
        "置換用の表示例:\n",
        "- `ret[1:] = np.clip(0.030183 * np.diff(score), -0.133621, 0.133621)`\n",
        "- `g = Garch11(alpha=0.176670, beta=0.700321).fit(returns)`\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Input 8\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "p = Path(\"/content/drive/MyDrive/pj-TERM/natural_capital_pipeline.py\")\n",
        "s = p.read_text(encoding=\"utf-8\")\n",
        "\n",
        "s = s.replace(\n",
        "    \"ret[1:] = np.clip(0.08 * np.diff(score), -0.3, 0.3)\",\n",
        "    \"ret[1:] = np.clip(0.030183 * np.diff(score), -0.133621, 0.133621)\",\n",
        ")\n",
        "\n",
        "s = s.replace(\n",
        "    \"g = Garch11().fit(returns)\",\n",
        "    \"g = Garch11(alpha=0.176670, beta=0.700321).fit(returns)\",\n",
        ")\n",
        "\n",
        "p.write_text(s, encoding=\"utf-8\")\n",
        "print(\"updated:\", p)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Output 8\n",
        "`updated: /content/drive/MyDrive/pj-TERM/natural_capital_pipeline.py`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Input 9\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys, importlib.util\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "\n",
        "SCRIPT = \"/content/drive/MyDrive/pj-TERM/natural_capital_pipeline.py\"\n",
        "CONFIG = \"/content/drive/MyDrive/pj-TERM/config_example.json\"\n",
        "\n",
        "sys.modules.pop(\"ncp\", None)\n",
        "spec = importlib.util.spec_from_file_location(\"ncp\", SCRIPT)\n",
        "ncp = importlib.util.module_from_spec(spec)\n",
        "sys.modules[\"ncp\"] = ncp\n",
        "spec.loader.exec_module(ncp)\n",
        "\n",
        "cfg = ncp.load_config(Path(CONFIG))\n",
        "rows = ncp.synthetic_weekly_rows(cfg)\n",
        "\n",
        "# 現在の式に合わせたreturns\n",
        "feature_names = [k for k in rows[0].keys() if k != \"week_start\"]\n",
        "x = np.array([[float(r[k]) for k in feature_names] for r in rows], dtype=np.float64)\n",
        "mu = x.mean(axis=0); sd = x.std(axis=0); sd[sd < 1e-9] = 1.0\n",
        "score = ((x - mu) / sd).mean(axis=1)\n",
        "ret = np.zeros(len(score), dtype=np.float64)\n",
        "ret[1:] = np.clip(0.030183 * np.diff(score), -0.133621, 0.133621)\n",
        "\n",
        "alpha, beta = 0.176670, 0.700321\n",
        "\n",
        "def rmse_on_slice(r, train_end):\n",
        "    tr = r[:train_end]\n",
        "    va = r[train_end:]\n",
        "    if len(tr) < 20 or len(va) < 5:\n",
        "        return np.nan\n",
        "    m = float(np.mean(tr))\n",
        "    e = tr - m\n",
        "    v0 = float(np.var(e)) + 1e-8\n",
        "    omega = max(1e-10, v0 * (1.0 - alpha - beta))\n",
        "    s2 = v0\n",
        "    e_prev = float(e[-1])\n",
        "\n",
        "    pred = []\n",
        "    for rr in va:\n",
        "        s2 = max(1e-10, omega + alpha * (e_prev**2) + beta * s2)\n",
        "        pred.append(s2)\n",
        "        e_prev = float(rr - m)\n",
        "    realized = (va - m) ** 2\n",
        "    return float(np.sqrt(np.mean((np.array(pred) - realized) ** 2)))\n",
        "\n",
        "cuts = [int(len(ret)*k) for k in [0.55, 0.60, 0.65, 0.70, 0.75]]\n",
        "scores = [rmse_on_slice(ret, c) for c in cuts]\n",
        "scores = [s for s in scores if np.isfinite(s)]\n",
        "\n",
        "print(\"walk-forward RMSEs:\", scores)\n",
        "print(\"mean RMSE:\", float(np.mean(scores)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Output 9\n",
        "`walk-forward RMSEs` と `mean RMSE` が表示\n",
        "\n",
        "- walk-forward RMSEs:\n",
        "  - `2.8806368007381736e-06`\n",
        "  - `2.911673340748027e-06`\n",
        "  - `3.0862704089505656e-06`\n",
        "  - `3.2402189833112497e-06`\n",
        "  - `3.4362797144937282e-06`\n",
        "- mean RMSE: `3.1110158496483492e-06`\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Input 10\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "base = Path(\"/content/drive/MyDrive/pj-TERM/cache/fujisawa_demo/derived\")\n",
        "\n",
        "idx = pd.read_csv(base / \"natural_capital_index.csv\")\n",
        "vol = pd.read_csv(base / \"volatility_forecast.csv\")\n",
        "signals = json.loads((base / \"finance_signals.json\").read_text(encoding=\"utf-8\"))\n",
        "\n",
        "idx[\"week_start\"] = pd.to_datetime(idx[\"week_start\"])\n",
        "idx = idx.sort_values(\"week_start\").reset_index(drop=True)\n",
        "idx[\"ret_vol_12w\"] = idx[\"ecological_return\"].rolling(12).std()\n",
        "\n",
        "thr = signals[\"derivative\"][\"vol_threshold\"]\n",
        "triggered = int(signals[\"derivative\"][\"triggered\"])\n",
        "payout_ratio_pct = 100 * signals[\"derivative\"][\"payout_ratio\"]\n",
        "base_coupon_pct = 100 * signals[\"nature_bond\"][\"base_coupon\"]\n",
        "final_coupon_pct = 100 * signals[\"nature_bond\"][\"final_coupon\"]\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 9), constrained_layout=True)\n",
        "\n",
        "# 1) Natural Capital Index\n",
        "axes[0, 0].plot(idx[\"week_start\"], idx[\"natural_capital_index\"], lw=2)\n",
        "axes[0, 0].set_title(\"Natural Capital Index\")\n",
        "axes[0, 0].set_xlabel(\"Week\")\n",
        "axes[0, 0].set_ylabel(\"Index\")\n",
        "axes[0, 0].grid(alpha=0.3)\n",
        "\n",
        "# 2) Ecological Return + 12-week vol\n",
        "ax2 = axes[0, 1]\n",
        "ax2.plot(idx[\"week_start\"], idx[\"ecological_return\"], lw=1.5, label=\"Ecological Return\")\n",
        "ax2.set_title(\"Ecological Return\")\n",
        "ax2.set_xlabel(\"Week\")\n",
        "ax2.set_ylabel(\"Return\")\n",
        "ax2.grid(alpha=0.3)\n",
        "\n",
        "ax2b = ax2.twinx()\n",
        "ax2b.plot(idx[\"week_start\"], idx[\"ret_vol_12w\"], ls=\"--\", lw=1.5, label=\"12w Volatility\")\n",
        "ax2b.set_ylabel(\"Volatility (std)\")\n",
        "\n",
        "l1, lb1 = ax2.get_legend_handles_labels()\n",
        "l2, lb2 = ax2b.get_legend_handles_labels()\n",
        "ax2.legend(l1 + l2, lb1 + lb2, loc=\"upper right\")\n",
        "\n",
        "# 3) Forecast variance\n",
        "axes[1, 0].plot(vol[\"horizon_week\"], vol[\"garch_sigma2\"], marker=\"o\", label=\"GARCH\")\n",
        "axes[1, 0].plot(vol[\"horizon_week\"], vol[\"transformer_sigma2\"], marker=\"s\", label=\"Transformer-like\")\n",
        "axes[1, 0].axhline(thr, color=\"red\", ls=\"--\", label=f\"Threshold={thr:.2e}\")\n",
        "axes[1, 0].set_title(\"Volatility Forecast (Sigma^2)\")\n",
        "axes[1, 0].set_xlabel(\"Horizon Week\")\n",
        "axes[1, 0].set_ylabel(\"Variance\")\n",
        "axes[1, 0].grid(alpha=0.3)\n",
        "axes[1, 0].legend()\n",
        "\n",
        "# 4) Finance summary bars\n",
        "labels = [\"Payout Ratio(%)\", \"Base Coupon(%)\", \"Final Coupon(%)\", \"Triggered(0/1)\"]\n",
        "vals = [payout_ratio_pct, base_coupon_pct, final_coupon_pct, triggered]\n",
        "axes[1, 1].bar(labels, vals)\n",
        "axes[1, 1].set_title(\"Finance Signals Summary\")\n",
        "axes[1, 1].grid(axis=\"y\", alpha=0.3)\n",
        "axes[1, 1].tick_params(axis=\"x\", rotation=20)\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Output 10\n",
        "2x2ダッシュボードプロット\n",
        "\n",
        "（チューニング後に再実行した結果の読み取り例）\n",
        "- `Triggered = 0`\n",
        "- `Payout Ratio = 0%`\n",
        "- `Base Coupon = 4.5%`\n",
        "- `Final Coupon = 4.9%`\n",
        "- `Threshold ≈ 7.34e-06`\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Input 11\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "\n",
        "feat = pd.read_csv(Path(\"/content/drive/MyDrive/pj-TERM/cache/fujisawa_demo/derived/features_weekly.csv\"))\n",
        "feat[\"week_start\"] = pd.to_datetime(feat[\"week_start\"])\n",
        "\n",
        "num_cols = [c for c in feat.columns if c != \"week_start\"]\n",
        "z = feat[num_cols].copy()\n",
        "z = (z - z.mean()) / z.std().replace(0, 1)\n",
        "\n",
        "plt.figure(figsize=(14, 5))\n",
        "for c in num_cols:\n",
        "    plt.plot(feat[\"week_start\"], z[c], label=c, alpha=0.9)\n",
        "plt.title(\"Weekly Features (Z-score normalized)\")\n",
        "plt.xlabel(\"Week\")\n",
        "plt.ylabel(\"Z-score\")\n",
        "plt.grid(alpha=0.3)\n",
        "plt.legend(ncol=3, fontsize=9)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Output 11\n",
        "`Weekly Features (Z-score normalized)` プロット\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Input 12\n",
        "画像を全て1回で保存（2panel / 2x2 / weekly features）\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "base = Path(\"/content/drive/MyDrive/pj-TERM/cache/fujisawa_demo/derived\")\n",
        "out_img = base / \"figures\"\n",
        "out_img.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Load data\n",
        "idx = pd.read_csv(base / \"natural_capital_index.csv\")\n",
        "vol = pd.read_csv(base / \"volatility_forecast.csv\")\n",
        "feat = pd.read_csv(base / \"features_weekly.csv\")\n",
        "signals = json.loads((base / \"finance_signals.json\").read_text(encoding=\"utf-8\"))\n",
        "\n",
        "idx[\"week_start\"] = pd.to_datetime(idx[\"week_start\"])\n",
        "idx = idx.sort_values(\"week_start\").reset_index(drop=True)\n",
        "idx[\"ret_vol_12w\"] = idx[\"ecological_return\"].rolling(12).std()\n",
        "feat[\"week_start\"] = pd.to_datetime(feat[\"week_start\"])\n",
        "\n",
        "# Figure 1: 2-panel\n",
        "fig1, axes = plt.subplots(2, 1, figsize=(12, 8), constrained_layout=True)\n",
        "ax1 = axes[0]\n",
        "ax1.plot(idx[\"week_start\"], idx[\"natural_capital_index\"], label=\"Natural Capital Index\")\n",
        "ax1.set_title(\"Natural Capital Index\")\n",
        "ax1.set_xlabel(\"Week\")\n",
        "ax1.set_ylabel(\"Index Level\")\n",
        "ax1.grid(True, alpha=0.3)\n",
        "ax1b = ax1.twinx()\n",
        "ax1b.plot(idx[\"week_start\"], idx[\"ecological_return\"], linestyle=\"--\", label=\"Ecological Return\")\n",
        "ax1b.set_ylabel(\"Return\")\n",
        "l1, lb1 = ax1.get_legend_handles_labels()\n",
        "l2, lb2 = ax1b.get_legend_handles_labels()\n",
        "ax1.legend(l1 + l2, lb1 + lb2, loc=\"best\")\n",
        "ax2 = axes[1]\n",
        "ax2.plot(vol[\"horizon_week\"], vol[\"garch_sigma2\"], marker=\"o\", label=\"GARCH Sigma^2\")\n",
        "ax2.plot(vol[\"horizon_week\"], vol[\"transformer_sigma2\"], marker=\"s\", label=\"Transformer Sigma^2\")\n",
        "ax2.set_title(\"Volatility Forecast\")\n",
        "ax2.set_xlabel(\"Horizon Week\")\n",
        "ax2.set_ylabel(\"Variance\")\n",
        "ax2.grid(True, alpha=0.3)\n",
        "ax2.legend(loc=\"best\")\n",
        "path1 = out_img / \"index_volatility_2panel.png\"\n",
        "fig1.savefig(path1, dpi=150, bbox_inches=\"tight\")\n",
        "plt.show()\n",
        "\n",
        "# Figure 2: 2x2 dashboard\n",
        "thr = signals[\"derivative\"][\"vol_threshold\"]\n",
        "triggered = int(signals[\"derivative\"][\"triggered\"])\n",
        "payout_ratio_pct = 100 * signals[\"derivative\"][\"payout_ratio\"]\n",
        "base_coupon_pct = 100 * signals[\"nature_bond\"][\"base_coupon\"]\n",
        "final_coupon_pct = 100 * signals[\"nature_bond\"][\"final_coupon\"]\n",
        "\n",
        "fig2, axes = plt.subplots(2, 2, figsize=(14, 9), constrained_layout=True)\n",
        "axes[0, 0].plot(idx[\"week_start\"], idx[\"natural_capital_index\"], lw=2)\n",
        "axes[0, 0].set_title(\"Natural Capital Index\")\n",
        "axes[0, 0].set_xlabel(\"Week\")\n",
        "axes[0, 0].set_ylabel(\"Index\")\n",
        "axes[0, 0].grid(alpha=0.3)\n",
        "axr = axes[0, 1]\n",
        "axr.plot(idx[\"week_start\"], idx[\"ecological_return\"], lw=1.5, label=\"Ecological Return\")\n",
        "axr.set_title(\"Ecological Return\")\n",
        "axr.set_xlabel(\"Week\")\n",
        "axr.set_ylabel(\"Return\")\n",
        "axr.grid(alpha=0.3)\n",
        "axrb = axr.twinx()\n",
        "axrb.plot(idx[\"week_start\"], idx[\"ret_vol_12w\"], ls=\"--\", lw=1.5, label=\"12w Volatility\")\n",
        "axrb.set_ylabel(\"Volatility (std)\")\n",
        "a, b = axr.get_legend_handles_labels()\n",
        "c, d = axrb.get_legend_handles_labels()\n",
        "axr.legend(a + c, b + d, loc=\"upper right\")\n",
        "axes[1, 0].plot(vol[\"horizon_week\"], vol[\"garch_sigma2\"], marker=\"o\", label=\"GARCH\")\n",
        "axes[1, 0].plot(vol[\"horizon_week\"], vol[\"transformer_sigma2\"], marker=\"s\", label=\"Transformer-like\")\n",
        "axes[1, 0].axhline(thr, color=\"red\", ls=\"--\", label=f\"Threshold={thr:.2e}\")\n",
        "axes[1, 0].set_title(\"Volatility Forecast (Sigma^2)\")\n",
        "axes[1, 0].set_xlabel(\"Horizon Week\")\n",
        "axes[1, 0].set_ylabel(\"Variance\")\n",
        "axes[1, 0].grid(alpha=0.3)\n",
        "axes[1, 0].legend()\n",
        "labels = [\"Payout Ratio(%)\", \"Base Coupon(%)\", \"Final Coupon(%)\", \"Triggered(0/1)\"]\n",
        "vals = [payout_ratio_pct, base_coupon_pct, final_coupon_pct, triggered]\n",
        "axes[1, 1].bar(labels, vals)\n",
        "axes[1, 1].set_title(\"Finance Signals Summary\")\n",
        "axes[1, 1].grid(axis=\"y\", alpha=0.3)\n",
        "axes[1, 1].tick_params(axis=\"x\", rotation=20)\n",
        "path2 = out_img / \"dashboard_2x2.png\"\n",
        "fig2.savefig(path2, dpi=150, bbox_inches=\"tight\")\n",
        "plt.show()\n",
        "\n",
        "# Figure 3: weekly features\n",
        "num_cols = [c for c in feat.columns if c != \"week_start\"]\n",
        "z = feat[num_cols].copy()\n",
        "z = (z - z.mean()) / z.std().replace(0, 1)\n",
        "fig3 = plt.figure(figsize=(14, 5))\n",
        "for c in num_cols:\n",
        "    plt.plot(feat[\"week_start\"], z[c], label=c, alpha=0.9)\n",
        "plt.title(\"Weekly Features (Z-score normalized)\")\n",
        "plt.xlabel(\"Week\")\n",
        "plt.ylabel(\"Z-score\")\n",
        "plt.grid(alpha=0.3)\n",
        "plt.legend(ncol=3, fontsize=9)\n",
        "path3 = out_img / \"weekly_features_zscore.png\"\n",
        "fig3.savefig(path3, dpi=150, bbox_inches=\"tight\")\n",
        "plt.show()\n",
        "\n",
        "print(\"saved:\")\n",
        "print(path1)\n",
        "print(path2)\n",
        "print(path3)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Output 12\n",
        "3枚の図を表示し、以下に保存\n",
        "- `/content/drive/MyDrive/pj-TERM/cache/fujisawa_demo/derived/figures/index_volatility_2panel.png`\n",
        "- `/content/drive/MyDrive/pj-TERM/cache/fujisawa_demo/derived/figures/dashboard_2x2.png`\n",
        "- `/content/drive/MyDrive/pj-TERM/cache/fujisawa_demo/derived/figures/weekly_features_zscore.png`\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}